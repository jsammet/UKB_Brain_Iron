df_noNA$CU_Low <- numeric(nrow(df_noNA))
df_noNA$CU_High <- numeric(nrow(df_noNA))
df_noNA$GroupCU[df_noNA$GROUP=='td'] <- 'TD'
df_noNA$GroupCU[df_noNA$GROUP=='cd' & df_noNA$ICU_trait<=ICU_CD_median] <- 'CD_CULow'
df_noNA$GroupCU[df_noNA$GROUP=='cd' & df_noNA$ICU_trait>ICU_CD_median] <- 'CD_CUHigh'
df_noNA$CU_Low[df_noNA$ICU_trait<=ICU_CD_median] <- 1
df_noNA$CU_High[df_noNA$ICU_trait>ICU_CD_median] <- 1
df_noNA$CU_High[df_noNA$CU_Low==1] <- 0
df_noNA$CU_Low[df_noNA$CU_High==1] <- 0
View(df_noNA)
df_cu_only_group <- select(df_noNA, -c('CU_Low','CU_High'))
df_cu_only_group_no_NA <- na.omit(df_cu_only_group)
# SAVE the files, both with and without "TD, CU_Low and CU_High" into folder if mounted on local PC
write.csv2(cu_noNA,file="/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu.csv", quote = FALSE)
write.csv2(df_cu_only_group,file="/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu_group_only.csv", quote = FALSE)
View(df_subj)
View(df_subj)
######################################### OWN PROJECT
df_subj <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu_group_only.csv",stringsAsFactors=FALSE,sep=";")
View(df_subj)
View(df_subj)
# Read list of existing participants
df_list <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/subjects.csv",stringsAsFactors=FALSE,sep=",", header=FALSE)
colnames(df_list) <- c("ID")
View(df_list)
### Merge data with available subjects
df_full = merge(x=df_data,y=df_list,by="ID",all.y=TRUE)
View(df_full)
######################################### OWN PROJECT
##GOAL: "ID", "GROUP", "GENDER", "AGE", "centre", "ICU_total_sum", "GroupCU", "CU_Low", "CU_High", "ADHD_acute", "anx_acute", "anx_life
df_reduced <- subset(df_full, select = c("ID","checklist_group","checklist_age","checklist_gender","checklist_hand","ICU_imp_total_sum_imp",
"IQ_e_total","ADHD_acute", "Anx_acute"))
# remove duplicates
df_reduced <- replace(df_reduced, df_reduced == "NaN", NA)
# Remove duplicates based on the 'id' column and keep rows with the lowest number of NAs
df_no_dupl <- df_reduced %>%
group_by(ID) %>%
mutate(na_count = rowSums(is.na(across()))) %>%
slice_min(order_by = na_count, with_ties = FALSE) %>%
select(-na_count) %>%
ungroup()
# Rename variables
oldnames = c("checklist_group","checklist_age","checklist_gender","checklist_hand","ICU_imp_total_sum_imp","IQ_e_total","Anx_acute")
newnames = c("GROUP","AGE","GENDER","HANDEDNESS","ICU_trait","IQ","Anxiety_acute")
df_rename <- df_no_dupl %>% rename_at(vars(oldnames), ~ newnames)
# Create centre variable by cutting of ID
df_rename$centre <- as.numeric(substr(df_rename$ID, 1, 2))
# change representative values
df_rename["GENDER"][df_rename["GENDER"] == '2'] <- 'm' #MALE
df_rename["GENDER"][df_rename["GENDER"] == '1'] <- 'f' #FEMALE
df_rename["GROUP"][df_rename["GROUP"] == 2] <- 'td' #CONTROL
df_rename["GROUP"][df_rename["GROUP"] == 1] <- 'cd' #CASE
df_no_onset <- df_rename#[, -which(names(df_rename) == 'age_onset')]
View(df_no_onset)
View(df_no_onset)
#Calculate age statistics of full set
df_no_onset$AGE <-as.numeric(df_no_onset$AGE)
df_no_onset$ICU_trait <-as.numeric(df_no_onset$ICU_trait)
# create dataframe without NA rows
df_noNA <- na.omit(df_no_onset)
View(df_noNA)
df_noNA$GroupCU <- vector("character", nrow(df_noNA))
df_noNA$CU_Low <- numeric(nrow(df_noNA))
df_noNA$CU_High <- numeric(nrow(df_noNA))
df_noNA$GroupCU[df_noNA$GROUP=='td'] <- 'TD'
df_noNA$GroupCU[df_noNA$GROUP=='cd' & df_noNA$ICU_trait<=ICU_CD_median] <- 'CD_CULow'
df_noNA$GroupCU[df_noNA$GROUP=='cd' & df_noNA$ICU_trait>ICU_CD_median] <- 'CD_CUHigh'
df_noNA$CU_Low[df_noNA$ICU_trait<=ICU_CD_median] <- 1
df_noNA$CU_High[df_noNA$ICU_trait>ICU_CD_median] <- 1
df_noNA$CU_High[df_noNA$CU_Low==1] <- 0
df_noNA$CU_Low[df_noNA$CU_High==1] <- 0
View(df_noNA)
df_cu_only_group <- select(df_noNA, -c('CU_Low','CU_High'))
View(df_cu_only_group)
View(df_cu_only_group)
# SAVE the files, both with and without "TD, CU_Low and CU_High" into folder if mounted on local PC
write.csv2(cu_noNA,file="/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu.csv", quote = FALSE)
write.csv2(df_cu_only_group,file="/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu_group_only.csv", quote = FALSE)
View(df_cu_only_group_no_NA)
View(df_cu_only_group_no_NA)
write.csv2(df_cu_only_group,file="/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu_group_only.csv", quote = FALSE,row.names=FALSE)
# SAVE the files, both with and without "TD, CU_Low and CU_High" into folder if mounted on local PC
write.csv2(cu_noNA,file="/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu.csv", quote = FALSE,row.names=FALSE)
write.csv2(df_cu_only_group,file="/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu_group_only.csv", quote = FALSE,row.names=FALSE)
View(df_cu_only_group)
View(df_cu_only_group)
df_list <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/Info_file_Arzie.csv",stringsAsFactors=FALSE,sep=",", header=FALSE)
df_list <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/Info_file_Arzie.csv",stringsAsFactors=FALSE, header=FALSE)
View(df_list)
df_list <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/Info_file_Arzie.csv",stringsAsFactors=FALSE, header=FALSE)
View(df_list)
df_list <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/Info_file_Arzie.csv",stringsAsFactors=FALSE,sep=";", header=FALSE)
View(df_list)
df_list <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/Info_file_Arzie.csv",stringsAsFactors=FALSE,sep=";", header=TRUE)
View(df_list)
#remove unwanted first line
df <- subset(df_list, select = -c("X"))
#remove unwanted first line
df <- subset(df_list, select = -c(X))
Vew(df)
View(df)
# Age
table(df$AGE)
mean(df$AGE)
View(df)
# N of CD/TD
table(df$GROUP)
table(df$GENDER[df$GROUP==1])
50/101
mean(df$AGE[df$GROUP==1])
mean(df$AGE[df$GROUP==2])
table(df$GENDER[df$GROUP==2])
105/167
# Maltreatment
table(df$MALTREATMENT)
# Maltreat for CD
table(df$MALTREATMENT[df$GROUP=1])
# Maltreat for CD
table(df$MALTREATMENT[df$GROUP==1])
mean(df$AGE[df$GROUP==1 && df$MALTREATMEN==1])
mean(df$AGE[df$GROUP==1 & df$MALTREATMEN==1])
# Maltreat for TD
table(df$MALTREATMENT[df$GROUP==2])
mean(df$AGE[df$GROUP==2 & df$MALTREATMEN==1])
df_josh <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu_group_only.csv",stringsAsFactors=FALSE,sep=";", header=TRUE)
View(df_josh)
View(df_josh)
table(df_josh$ICU_trait[df_josh$GROUP=cd])
table(df_josh$ICU_trait[df_josh$GROUP==cd])
table(df_josh$ICU_trait[df_josh$GROUP=='cd'])
table(df_josh$ICU_trait[df_josh$GROUP=='td'])
# Range for Anxiety
table(df_josh$ICU_trait[df_josh$Anxiety_acute==1])
# Range for Anxiety
table(df_josh$Anxiety_acute[df_josh$GROUP=='cd'])
table(df_josh$Anxiety_acute[df_josh$GROUP=='td'])
# Range for ICU
table(df_josh$ADHD_acute[df_josh$GROUP=='cd'])
table(df_josh$ADHD_acute[df_josh$GROUP=='td'])
df_josh <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu_group_only.csv",stringsAsFactors=FALSE,sep=";", header=TRUE)
table(df_josh$ICU_trait[df_josh$GROUP==cd])
table(df_josh$ICU_trait[df_josh$GROUP=='cd'])
# Age
table(df_josh$AGE)
mean(df_josh$AGE)
sd(df_josh$AG)
View(df_josh)
df_josh <- read.csv("/home/jsammet/mnt_bas/results_100M/scripts_data/complete_info_cu_group_only.csv",stringsAsFactors=FALSE,sep=";", header=TRUE)
View(df_josh)
table(df_josh$ICU_trait[df_josh$GROUP=='cd'])
# Age
table(df_josh$AGE)
mean(df_josh$AGE)
sd(df_josh$AG)
table(df_josh$GROUP)
# GENDER
table(df_josh$GENDER)
166/304
# Age
table(df_josh$AGE)
mean(df_josh$AGE)
sd(df_josh$AG)
# ICU
mean(df_josh$ICU_trait)
mean(df_josh$ICU_trait[df_josh$GROUP=='cd'])
sd(df_josh$ICU_trait[df_josh$GROUP=='cd'])
mean(df_josh$ICU_trait[df_josh$GROUP=='td'])
sd(df_josh$ICU_trait[df_josh$GROUP=='td'])
#ADHD
table(df_josh$ADHD_acute[df_josh$GROUP=='cd'])
table(df_josh$ADHD_acute[df_josh$GROUP=='td'])
#Anxiety
table(df_josh$Anxiety_acute[df_josh$GROUP=='cd'])
table(df_josh$Anxiety_acute[df_josh$GROUP=='td'])
info_df <- read.csv("swi_brain_vol_info.csv")
library(dplyr)
library(psych)
library(nFactors)
library(base)
library(corrplot)
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
getwd()
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
getwd()
info_df <- read.csv("swi_brain_vol_info.csv")
quantile(info_df$hb_concent, prob=c(1/3,2/3))
mean(info_df$age)
sd(info_df$age)
table(info_df$age)
median(info_df$age)
count(info_df$hb_concent<13.63)
sum(info_df$hb_concent<13.63, na.rm=TRUE)
sum(info_df$hb_concent>13.63 & info_df$hb_concent<14.7, na.rm=TRUE)
sum(info_df$hb_concent>14.7, na.rm=TRUE)
1476+1459+1471
sum(info_df$hb_concent<13.63, na.rm=TRUE)
sum(info_df$hb_concent>=13.63 & info_df$hb_concent<14.7, na.rm=TRUE)
sum(info_df$hb_concent>=14.7, na.rm=TRUE)
1476+1470+1490
results <- read.csv("/home/jsammet/mnt_ox/UKB_Brain_Iron/results/final_runs/test__flip_final_scheduler12_hb_concent_3class_200_0.0001_5e-07.csv")
# Check accuracy
min_ <- min(results$True_Label)
max_ <- max(results$True_Label)
Sensitivity <- 0
Specificity <- 0
Accuracy <- 0
for (i in min_:max_) {
i
TP_ <- nrow(results[ which(results$Prediction == i & results$True_Label == i) ,])
FP_ <- nrow(results[ which(results$Prediction == i & results$True_Label != i) ,])
FN_ <- nrow(results[ which(results$Prediction != i & results$True_Label == i) ,])
TN_ <- nrow(results[ which(results$Prediction != i & results$True_Label != i) ,])
Sensitivity <- Sensitivity + TP_ / (TP_ + FN_)
Specificity <- Specificity + TN_ / (TN_ + FP_)
Accuracy <- Accuracy + TP_
}
Sensitivity <- Sensitivity / (max_+1)
Specificity <- Specificity / (max_+1)
Accuracy <- Accuracy / length(results$True_Label)
Sensitivity
Specificity
Accuracy
results <- read.csv("/home/jsammet/mnt_ox/UKB_Brain_Iron/results/train_valid__hb_concent_no_batch_model_False_augment_100_eps_3_class_0.0001_lr_NT_IntGrad.csv")
# Check accuracy
min_ <- min(results$True_Label)
max_ <- max(results$True_Label)
Sensitivity <- 0
Specificity <- 0
Accuracy <- 0
for (i in min_:max_) {
i
TP_ <- nrow(results[ which(results$Prediction == i & results$True_Label == i) ,])
FP_ <- nrow(results[ which(results$Prediction == i & results$True_Label != i) ,])
FN_ <- nrow(results[ which(results$Prediction != i & results$True_Label == i) ,])
TN_ <- nrow(results[ which(results$Prediction != i & results$True_Label != i) ,])
Sensitivity <- Sensitivity + TP_ / (TP_ + FN_)
Specificity <- Specificity + TN_ / (TN_ + FP_)
Accuracy <- Accuracy + TP_
}
View(results)
View(results)
results <- read.csv("/home/jsammet/mnt_ox/UKB_Brain_Iron/results/test__hb_concent_no_batch_model_False_augment_100_eps_3_class_0.0001_lr_NT_IntGrad_seed_1337.csv")
# Check accuracy
min_ <- min(results$True_Label)
max_ <- max(results$True_Label)
Sensitivity <- 0
Specificity <- 0
Accuracy <- 0
for (i in min_:max_) {
i
TP_ <- nrow(results[ which(results$Prediction == i & results$True_Label == i) ,])
FP_ <- nrow(results[ which(results$Prediction == i & results$True_Label != i) ,])
FN_ <- nrow(results[ which(results$Prediction != i & results$True_Label == i) ,])
TN_ <- nrow(results[ which(results$Prediction != i & results$True_Label != i) ,])
Sensitivity <- Sensitivity + TP_ / (TP_ + FN_)
Specificity <- Specificity + TN_ / (TN_ + FP_)
Accuracy <- Accuracy + TP_
}
Sensitivity <- Sensitivity / (max_+1)
Specificity <- Specificity / (max_+1)
Accuracy <- Accuracy / length(results$True_Label)
Sensitivity
Specificity
Accuracy
results <- read.csv("/home/jsammet/mnt_ox/UKB_Brain_Iron/results/test__hb_concent_batch_model_False_augment_60_eps_3_class_0.0001_lr_NT_IntGrad_seed_1337.csv")
min_ <- min(results$True_Label)
max_ <- max(results$True_Label)
Sensitivity <- 0
Specificity <- 0
Accuracy <- 0
for (i in min_:max_) {
i
TP_ <- nrow(results[ which(results$Prediction == i & results$True_Label == i) ,])
FP_ <- nrow(results[ which(results$Prediction == i & results$True_Label != i) ,])
FN_ <- nrow(results[ which(results$Prediction != i & results$True_Label == i) ,])
TN_ <- nrow(results[ which(results$Prediction != i & results$True_Label != i) ,])
Sensitivity <- Sensitivity + TP_ / (TP_ + FN_)
Specificity <- Specificity + TN_ / (TN_ + FP_)
Accuracy <- Accuracy + TP_
}
Sensitivity <- Sensitivity / (max_+1)
Specificity <- Specificity / (max_+1)
Accuracy <- Accuracy / length(results$True_Label)
Sensitivity
Specificity
Accuracy
# Plot loss
loss <- read.csv("/home/jsammet/mnt_ox/UKB_Brain_Iron/results/final_runs/test_final_hb_concent_3class_60_0.0001_5e-07.csv")
plot(loss$ID,loss$train_loss,type = "l", lty = 1,col="red",xlab="epochs",ylab="Cross_entropy Loss",
main="3 class: Loss for training & validation for hb concentration",
ylim=c(0.55,1.2),cex.lab=1.3, cex.axis=1.3, cex.main=1.5)
# Plot loss
loss <- read.csv("/home/jsammet/mnt_ox/UKB_Brain_Iron/results/final_runs/train_valid_final_60_3class__0.0001hb_concent.csv")
plot(loss$ID,loss$train_loss,type = "l", lty = 1,col="red",xlab="epochs",ylab="Cross_entropy Loss",
main="3 class: Loss for training & validation for hb concentration",
ylim=c(0.55,1.2),cex.lab=1.3, cex.axis=1.3, cex.main=1.5)
lines(loss$ID,loss$valid,type = "l", lty = 1,col="green")
plot(loss$ID,loss$train_loss,type = "l", lty = 1,col="red",xlab="epochs",ylab="Cross_entropy Loss",
main="3 class: Loss for training & validation for hb concentration",
ylim=c(0.55,1.3),cex.lab=1.3, cex.axis=1.3, cex.main=1.5)
lines(loss$ID,loss$valid,type = "l", lty = 1,col="green")
legend(x = "topright",   # Position
inset = 0.1, cex=1.5,
legend = c("train loss", "valid loss"),  # Legend texts
lty = c(1, 1),           # Line types
col = c(2, 3),           # Line colors
lwd = 2)                 # Line width
# Plot loss
loss <- read.csv("/home/jsammet/mnt_ox/UKB_Brain_Iron/results/final_runs/train_valid_final_60_3class__0.0001hb_concent.csv")
View(loss)
png("plot.png", res = 1200)
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
png("plot.png", res = 1200, width = 8, height = 6, units = "in")
par(mar = c(4, 4, 1, 1))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
dev.off()
png("plot.png", res = 1200, width = 8, height = 6, units = "in")
par(mar = c(5, 4, 2, 2))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
png("plot.png", res = 1200, width = 8, height = 6, units = "in")
par(mar = c(5, 4, 2, 2))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
dev.off()
png("plot.png", res = 1200, width = 8, height = 6, units = "in")
par(mar = c(4, 4, 4, 1))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
dev.off()
png("plot.png", res = 1200, width = 8, height = 6, units = "in")
par(mar = c(4, 8, 1, 1))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
dev.off()
png("plot.png", res = 1200, width = 9, height = 6, units = "in")
par(mar = c(4, 6, 1, 1))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
dev.off()
png("plot.png", res = 1200, width = 9, height = 6, units = "in")
par(mar = c(4, 4, 2, 1))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
dev.off()
png("plot.png", res = 1200, width = 9, height = 6, units = "in")
par(mar = c(5, 5, 2, 1))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
dev.off()
png("plot.png", res = 1200, width = 9, height = 6, units = "in")
par(mar = c(4, 5, 2, 1))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
dev.off()
png("plot.png", res = 1200, width = 9, height = 6, units = "in")
par(mar = c(4.5, 5, 2, 1))  # Adjust margin values as needed
plot(loss$ID, loss$train_loss, type = "l", lty = 1, col = "red", xlab = "epochs", ylab = "Cross_entropy Loss",
main = "3 class: Loss for training & validation for hb concentration",
ylim = c(0.55, 1.3), cex.lab = 1.3, cex.axis = 1.3, cex.main = 1.5)
lines(loss$ID, loss$valid, type = "l", lty = 1, col = "green")
legend(x = "topright", inset = 0.1, cex = 1.5,
legend = c("train loss", "valid loss"),
lty = c(1, 1),
col = c(2, 3),
lwd = 2)
dev.off()
# Plot distribution of blood measures
hist(file_fin$erythrocyte_dist_wdt, breaks=60,cex.axis=1.5,cex.lab=1.5, cex.main=1.5, xlab = "Erythrocyte distribution width", main="Histogram of Erythrocyte distribution width")
hist(swi_joint$hb_concent, breaks=100, xlab = "Hb concentration", main = "Distribution of hb concentration")
swi_joint <- read.csv('swi_brain_vol_info_additional.csv')
library(dplyr)
library(psych)
library(nFactors)
library(base)
library(corrplot)
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
getwd()
swi_joint <- read.csv('swi_brain_vol_info_additional.csv')
hist(swi_joint$hb_concent, breaks=100, xlab = "Hb concentration", main = "Distribution of hb concentration")
full_file <- read.csv("final_brain_vol_info.csv")
h <- hist(full_file$hb_concent, breaks=100)
perc <- quantile(full_file$hb_concent, c(.1, .2, .3, .4, .5, .6, .7, .8, .9, 1))
cuts <- cut(h$breaks, perc)
# plot the histogram with the colours
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink")[cuts],main="Mean corp hb using min & max",
xlab="Mean corp hb",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
perc <- quantile(full_file$hb_concent, c(0,.1, .2, .3, .4, .5, .6, .7, .8, .9, 1))
cuts <- cut(h$breaks, perc)
# plot the histogram with the colours
png("histo_10cl.png", res = 1200, width = 9, height = 6, units = "in")
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink")[cuts],main="Hb concentration in 10 percentiles",
xlab="Mean corp hb",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
dev.off()
pwd
getwd()
h <- hist(full_file$hb_concent, breaks=100)
perc <- quantile(full_file$hb_concent, c(0,.1, .2, .3, .4, .5, .6, .7, .8, .9, 1))
cuts <- cut(h$breaks, perc)
# plot the histogram with the colours
png("histo_10cl.png", res = 1200, width = 9, height = 6, units = "in")
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink","silver")[cuts],main="Hb concentration in 10 percentiles",
xlab="Mean corp hb",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink","gray")[cuts],main="Hb concentration in 10 percentiles",
xlab="Mean corp hb",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
dev.off()
perc <- quantile(full_file$hb_concent, c(0, 1/3, 2/3 , 1)) # for 3 groups
cuts <- cut(h$breaks, perc)
# plot the histogram with the colours
png("histo_10cl.png", res = 1200, width = 9, height = 6, units = "in")
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink","gray")[cuts],main="Hb concentration in 3 percentiles",
xlab="Mean corp hb",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
# plot the histogram with the colours
png("histo_3cl.png", res = 1200, width = 9, height = 6, units = "in")
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink","gray")[cuts],main="Hb concentration in 3 percentiles",
xlab="Mean corp hb",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
dev.off()
png("histo_3cl.png", res = 1200, width = 9, height = 6, units = "in")
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink","gray")[cuts],main="Hb concentration in 3 percentiles",
xlab="Hb concentration",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
dev.off()
perc <- quantile(full_file$hb_concent, c(0,.1, .2, .3, .4, .5, .6, .7, .8, .9, 1)) # for 10 groups
# plot the histogram with the colours
png("histo_10cl.png", res = 1200, width = 9, height = 6, units = "in")
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink","gray")[cuts],main="Hb concentration in 10 percentiles",
xlab="Hb concentration",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
dev.off()
perc <- quantile(full_file$hb_concent, c(0,.1, .2, .3, .4, .5, .6, .7, .8, .9, 1)) # for 10 groups
# plot the histogram with the colours
png("histo_10cl.png", res = 1200, width = 9, height = 6, units = "in")
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink","gray")[cuts],main="Hb concentration in 10 percentiles",
xlab="Hb concentration",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
dev.off()
cuts <- cut(h$breaks, perc)
# plot the histogram with the colours
png("histo_10cl.png", res = 1200, width = 9, height = 6, units = "in")
plot(h, col=c("green","red","blue","orange","cyan","white","black","yellow","pink","gray")[cuts],main="Hb concentration in 10 percentiles",
xlab="Hb concentration",cex.axis=1.5, cex.lab=1.3, cex.main=1.5)
dev.off()
